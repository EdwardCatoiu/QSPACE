{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the qspace class\n",
    "from qspace import QSPACE\n",
    "import os.path as op\n",
    "\n",
    "# ProjectName = 'QSPACE-24_example'\n",
    "# ProjectName = 'QSPACE-1515'\n",
    "ProjectName = 'QSPACE-GS'\n",
    "\n",
    "# geneListInput = '000A-gene_list_example24.txt' #Example run \n",
    "# geneListInput = '000A-gene_list_iML1515.txt' # iML1515\n",
    "geneListInput = '000A-gene_list_4349.txt' # Genome-Scale\n",
    "\n",
    "# force_rerun_global = True  #this is run #1\n",
    "force_rerun_global = False  #this is run #2  < use this to avoid re-downloading seq/struct files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/home/ecatoiu/Projects/QSPACE/'\n",
    "RESULTS_DIR = '/home/ecatoiu/Projects/QSPACE_ecoli_results/'\n",
    "EXTERNAL_HARDDRIVE_DIR =  '../../../../../../../mnt/wwn-0x5000c500b96b98e1-part1/QSPACE_ecoli/'\n",
    "# SSBIO_DIR = '/home/ecatoiu/SBRG_github_clone_old_working/ssbio/'\n",
    "INPUT_DIR = op.join(ROOT_DIR, 'Manuscript/Inputs/')  #leave as is to run example/QS-1515/QS-GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "swissRepositoryFolder = '../../../../../mnt/wwn-0x5000c500b96b98e1-part1/QSPACE_ecoli/inputs/SWISS-MODEL-Repository/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/Bio/pairwise2.py:283: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  BiopythonDeprecationWarning,\n"
     ]
    }
   ],
   "source": [
    "qspace = QSPACE(ProjectName=ProjectName, root_dir=ROOT_DIR, external_hardDrive_dir=EXTERNAL_HARDDRIVE_DIR,results_dir=RESULTS_DIR, input_dir=INPUT_DIR)#, ssbio_dir = SSBIO_DIR)\n",
    "\n",
    "import time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()\n",
    "time_global_start = time.time()\n",
    "import math\n",
    "\n",
    "def get_computation_time(label, time_start):\n",
    "    \n",
    "    \n",
    "    minutes = math.floor((time.time() - time_start) / 60.)\n",
    "    seconds = (time.time() - time_start) % 60.\n",
    "    print (\"{} :  {:.1f}m  {:.1f}s\".format(label, minutes, seconds))\n",
    "    return time.time() - time_start\n",
    "    \n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles, venn3_unweighted\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import os\n",
    "from importlib import reload\n",
    "import json\n",
    "import ast\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "#import qspace functions\n",
    "sys.path.append(qspace.FunctionsDir)\n",
    "from functions import prepare_structures_for_BFS as prepBFS\n",
    "from functions import  oligomerization\n",
    "from functions import  bfs_algo\n",
    "from functions import  pseudo_structures as pseudo\n",
    "from functions import  read_uniprot_text\n",
    "\n",
    "import _sequenceModule as sequenceModule\n",
    "import _homologyModule as homologyModule\n",
    "import _pdbModule as pdbModule\n",
    "import _figuresModule as figuresModule\n",
    "import _proteinTargetAnnotationModule as pTAM\n",
    "import _proteinToStructuresModule as pTSM\n",
    "import _membraneModule as membraneModule\n",
    "import _structuralPropertiesModule as structuralPropertiesModule\n",
    "import _mutantFunctionModule as mutantFunctionModule\n",
    "import _compileDataModule as compileDataModule\n",
    "\n",
    "from _structuralPropertiesModule import utils as structuralPropUtils\n",
    "\n",
    "runTimeFile = op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global))\n",
    "if op.exists(runTimeFile):\n",
    "    with open (runTimeFile,'r' ) as f:\n",
    "        comp_time_data = json.load(f)\n",
    "else:\n",
    "    comp_time_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Module (#000A-C)\n",
    "\n",
    "- <b>#000A</b> --  Determine UniProt IDs for a list of genes\n",
    "- <b>#000B</b> --  Download UniProt Sequences (.txt and .fasta)\n",
    "- <b>#000C</b> --  Download Alleleome Sequences (.fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Blattner - UniProt Mapping  ( #000A )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sequenceModule.run_000A.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "\n",
    "blattnerUniprotMapping, qspacegeneList = sequenceModule.run_000A(geneListInput = geneListInput, #initialized at start\n",
    "                                                           UniprotQueryInput = '000A-uniprot_ids_from_websearch.xlsx',\n",
    "                                                           manual_correction = True,\n",
    "                                                           trim = True,\n",
    "                                                          )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '000A', time_start=time_block_start)\n",
    "comp_time_data.update({'0A' : time_point})\n",
    "\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download UniProt Sequences  ( #000B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "sequenceModule.run_000B(blattnerUniprotMapping=blattnerUniprotMapping,\n",
    "                    force_rerun = False)\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '000B', time_start=time_block_start)\n",
    "comp_time_data.update({'0B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download WT Alleleome Sequences  ( #000C )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alleleome Sequences can be found at https://github.com/EdwardCatoiu/Alleleome\n",
    "\n",
    "if using Alleleome_Data/dfz (recommended)\n",
    "- clone repo. set path to folder\n",
    "\n",
    "if using data in Datasets folder....\n",
    "- download the dataframes\n",
    "- merge the dataframes\n",
    "- seperate the dataframes by gene Id (Blattner Number)\n",
    "- save the gene-dataframes into folder\n",
    "- change input folder below \n",
    "\n",
    "\n",
    "\n",
    "####  -------OR---------\n",
    "\n",
    "- comment the block out and skip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "sequenceModule.run_000C(alleleomeInputFolder='/home/ecatoiu/Projects/Alleleome/Alleleome_Data/dfz',\n",
    "                        geneListInput = geneListInput,\n",
    "                        force_rerun = False\n",
    "\n",
    "                       )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '000C', time_start=time_block_start)\n",
    "comp_time_data.update({'0C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Sequence Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homology Module (#001A-C)\n",
    "\n",
    "- <b>#001A</b> --  Download Alphafold models, assess quality\n",
    "- <b>#001B</b> --  Download SWISS-models, assess quality\n",
    "- <b>#001C</b> --  Download ITASSER models, assess quality\n",
    "- <b>#001D</b> --  Sequence alignment of UniProt/WT sequences to all models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alphafold DB  ( #001A )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dfalphafold_monomer = homologyModule.run_001A(blattnerUniprotMapping=blattnerUniprotMapping,\n",
    "                                              force_redownload= False,\n",
    "                                              force_realign= force_rerun_global,\n",
    "                                              alphafoldStructuresDir= False,\n",
    "                                              alphafoldMetricsDir= False\n",
    "                                             )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '001A', time_start=time_block_start)\n",
    "comp_time_data.update({'1A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SWISS MODEL ( #001B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "\n",
    "homologyModule.run_001B(blattnerUniprotMapping =blattnerUniprotMapping,\n",
    "                        swissRepositoryFolder = swissRepositoryFolder,\n",
    "                        force_realign= force_rerun_global,\n",
    "                    )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '001B', time_start=time_block_start)\n",
    "comp_time_data.update({'1B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I-TASSER  ( #001C )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infile = op.join(qspace.Input_dir, '001C-ITASSER_raw_metadata_hyperlink.csv')\n",
    "infile_wScores = op.join(qspace.DataOutput_dir, '001C-ITASSER_raw_metadata_hyperlink_tmscores.csv')\n",
    "if op.exists(infile_wScores):\n",
    "    itasser_metadata = pd.read_csv(infile_wScores, index_col=0)\n",
    "    needs_scoring = False\n",
    "else:\n",
    "    itasser_metadata = pd.read_csv(infile, index_col=0)\n",
    "    needs_scoring = True\n",
    "  \n",
    "\n",
    "itasser_metadata = itasser_metadata[itasser_metadata.index.isin(blattnerUniprotMapping.values())]   \n",
    "itasserRepoFolder = '../../../../../../../../mnt/wwn-0x5000c500b96b98e1-part1/qspace/GEMPRO/structures/ITASSER-MODEL-Repository/'\n",
    "needs_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "df_itasser_outliers = homologyModule.run_001C(itasser_metadata = itasser_metadata,\n",
    "                                              itasserRepoFolder = itasserRepoFolder, \n",
    "                                              blattnerUniprotMapping = blattnerUniprotMapping,\n",
    "                                              needs_scoring = needs_scoring,\n",
    "                                              force_clean  = False, #True when using for first time\n",
    "                                              force_realign = False,#True when using for first time\n",
    "                                              force_remove_string = False, #True when using for first time\n",
    "#                                               save_outliers = True,#True when using\n",
    "                    )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '001C', time_start=time_block_start)\n",
    "comp_time_data.update({'1C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alignment ( #001D )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dfseq = homologyModule.run_001D(genelist = qspacegeneList, \n",
    "                                blattnerUniprotMapping = blattnerUniprotMapping,\n",
    "                                force_rerun = force_rerun_global,\n",
    "                                itasser = True,\n",
    "                                alphafold = True,\n",
    "                                swiss = True,\n",
    "                                itasser_metadata = itasser_metadata)\n",
    "\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '001D', time_start=time_block_start)\n",
    "comp_time_data.update({'1D' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)\n",
    "dfseq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Pseudo-structure Homology ( # 001E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "####SWISS MODELS\n",
    "\n",
    "swiss_model_metrics = op.join(swissRepositoryFolder ,'INDEX.csv')\n",
    "dfswiss_model_metrics = pd.read_csv(swiss_model_metrics, skiprows=6, sep ='\\t')\n",
    "\n",
    "with open(op.join(qspace.DataOutput_dir, '001D-quality_of_swiss_models.json'), 'rb') as f:\n",
    "    input_quality = json.load(f)\n",
    "\n",
    "dfpseudo_swiss, dfpseudo_swiss_best =  homologyModule.run_001E(input_quality = input_quality,\n",
    "                                                               dfseq=dfseq,\n",
    "                                                               query_type = 'SWISS',\n",
    "                                                               dfswiss_model_metrics=dfswiss_model_metrics\n",
    "                                                              )\n",
    "####ITASSER MODELS\n",
    "with open(op.join(qspace.DataOutput_dir, '001D-quality_of_itasser_models.json'), 'rb') as f:\n",
    "    input_quality = json.load(f)\n",
    "\n",
    "dfpseudo_itasser, dfpseudo_itasser_best =  homologyModule.run_001E(input_quality = input_quality,\n",
    "                                                               dfseq=dfseq,\n",
    "                                                               query_type = 'ITASSER',\n",
    "                                                              )\n",
    "\n",
    "####Alphafold Models\n",
    "with open(op.join(qspace.DataOutput_dir, '001A-quality_of_alphafold_monomers.json'), 'rb') as f:\n",
    "    input_quality = json.load(f)\n",
    "\n",
    "dfpseudo_alphafold, dfpseudo_alphafold_best= homologyModule.run_001E(input_quality = input_quality,\n",
    "                                                                        dfseq=dfseq,\n",
    "                                                                        query_type = 'ALPHAFOLD',\n",
    "                                                                       )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '001E', time_start=time_block_start)\n",
    "comp_time_data.update({'1E' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Homology Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDB Module (#002A)\n",
    "- <b>#002A</b> --  PDB search API - TextService / SequenceService  \n",
    "- <b>#002B</b> --  Download PDB Bioassemblies\n",
    "- <b>#002C</b> --  Transfer API search data from PDBs to Bioassemblies and determine oligomeric state\n",
    "- <b>#002D</b> --  Get pseudo-structures from bioassemblies, replace mmSeqs2-API score with sequence identity (needle-alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(op.join(qspace.DataOutput_dir, \"000A-uniprot_blattner_mapping.json\"), 'rb') as f:\n",
    "    blattnerUniprotMapping = json.load(f)\n",
    "dfseq = op.join(qspace.DataOutput_dir, '001D-dfrepseq.csv')\n",
    "dfseq = pd.read_csv(dfseq, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 002A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = op.join(qspace.DataOutput_dir,'002A-uniprot_to_pdb.csv')\n",
    "infile_fullinfo = op.join(qspace.DataOutput_dir,'002A-uniprot_to_pdb_full_info.csv') \n",
    "\n",
    "if op.exists(infile) and op.exists(infile_fullinfo) and not force_rerun_global:\n",
    "    textService_UniToPDB = pd.read_csv(infile)\n",
    "    textService_PDBinfo = pd.read_csv(infile_fullinfo)\n",
    "\n",
    "else:\n",
    "    textService_UniToPDB, textService_PDBinfo =  pdbModule.run_002A_textService(blattner_uniprot_mapping=blattnerUniprotMapping,\n",
    "                                                                         bestStructuresDir=qspace.bestStructuresDir,\n",
    "                                                                         force_ssbio_map = force_rerun_global,\n",
    "                                                                         force_rerun_PDB_api= force_rerun_global,\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_type = \"UniProt\"\n",
    "json_file_uniprot = op.join(qspace.DataOutput_dir,'002A-BLAST_PDB_{}Seq.json'.format(query_type)) \n",
    "force_genes = set() #add gene Ids that you want to force a re-run of PDB Sequence service for \n",
    "\n",
    "if op.exists(json_file_uniprot) and not force_rerun_global and len(force_genes) == 0:\n",
    "    with open(json_file_uniprot, 'rb') as f:\n",
    "        sequenceService_UniProt = json.load(f)\n",
    "    sequenceService_UniProt = ast.literal_eval(sequenceService_UniProt)\n",
    "    \n",
    "else:\n",
    "    #will run sequence service for all genes not already in results dictionary\n",
    "    #will run sequence service for all genes in 'force_genes', override the old data\n",
    "    sequenceService_UniProt = pdbModule.run_002A_sequenceService(blattner_uniprot_mapping=blattnerUniprotMapping, \n",
    "                                                                 dfseq=dfseq, \n",
    "                                                                 query_type = query_type,\n",
    "                                                                 force_rerun_api = force_rerun_global,\n",
    "                                                                 force_genes =force_genes,\n",
    "                                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_type = \"Alleleome\"\n",
    "json_file_alleleome = op.join(qspace.DataOutput_dir,'002A-BLAST_PDB_{}Seq.json'.format(query_type)) \n",
    "\n",
    "if op.exists(json_file_alleleome)  and not force_rerun_global and len(force_genes) == 0:\n",
    "    with open(json_file_alleleome, 'rb') as f:\n",
    "        sequenceService_Alleleome = json.load(f)\n",
    "    sequenceService_Alleleome = ast.literal_eval(sequenceService_Alleleome)\n",
    "else: \n",
    "    #will run sequence service for all genes not already in results dictionary\n",
    "    #will run sequence service for all genes in 'force_genes', override the old data\n",
    "    sequenceService_Alleleome = pdbModule.run_002A_sequenceService(blattner_uniprot_mapping=blattnerUniprotMapping, \n",
    "                                                                   dfseq=dfseq, \n",
    "                                                                   query_type = query_type,\n",
    "                                                                   force_rerun_api = force_rerun_global,\n",
    "                                                                   force_genes =force_genes,\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = op.join(qspace.DataOutput_dir, '002A-ALL_mapped_PDBS.csv')\n",
    "if op.exists(infile) and not force_rerun_global:\n",
    "    allMappedPDBs_PDBinfo = pd.read_csv(infile,index_col=0)  \n",
    "\n",
    "else:\n",
    "    # Get a list of all PDB entries that were mapped from the Sequence Servie queries (UniProt and Alleleome)\n",
    "\n",
    "    sequenceService_all_mapped_pdbs = []\n",
    "    for api_result in [sequenceService_Alleleome,sequenceService_UniProt ]:\n",
    "        for gene, mapped_pdbs in api_result.items():\n",
    "            sequenceService_all_mapped_pdbs += mapped_pdbs.keys()\n",
    "    sequenceService_all_mapped_pdbs = list(set(sequenceService_all_mapped_pdbs))\n",
    "    #Get the PDB info\n",
    "    sequenceService_PDBinfo = pdbModule.textService_getPdbInfo(list_of_PDB_entries=sequenceService_all_mapped_pdbs)\n",
    "\n",
    "\n",
    "    #get a list of all PDBs mapped from both ssbio-UniProt text service and AAseq sequence service APIs\n",
    "    appender_string = []\n",
    "    appender = []\n",
    "    for record in list( textService_PDBinfo.to_records(index=False)):\n",
    "        if str(list(record)) not in appender_string:\n",
    "            appender += [record]\n",
    "            appender_string += [str(list(record))]\n",
    "\n",
    "    for record in list( sequenceService_PDBinfo.to_records(index=False)):\n",
    "        if str(list(record)) not in appender_string:\n",
    "            appender += [record]\n",
    "            appender_string += [str(list(record))]\n",
    "    #get the information for all mapped PDBs\n",
    "    allMappedPDBs_PDBinfo = pd.DataFrame.from_records(appender, columns=[u'pdb_entry', u'entity_id', u'asym_ids', u'auth_asym_ids',\n",
    "                                                      u'databaseName', u'databaseId', u'seq', u'polymer_entity_seq_len',\n",
    "                                                      u'entity_macro_type', u'formula_weight'])\n",
    "\n",
    "    print ('All mapped PDBs to our list of genes...')\n",
    "    outfile = op.join(qspace.DataOutput_dir, '002A-ALL_mapped_PDBS.csv')\n",
    "    allMappedPDBs_PDBinfo.to_csv(outfile)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = op.join(qspace.DataOutput_dir, '002A-PDBstructureInfo.csv')\n",
    "if op.exists(infile) and not force_rerun_global:\n",
    "    dfpdb_structure_info = pd.read_csv(infile,index_col=0) \n",
    "else:\n",
    "    dfpdb_structure_info = pdbModule.run_002A_structureInfo(PDB_files=allMappedPDBs_PDBinfo.pdb_entry.unique(),\n",
    "                                                        force_rerun = force_rerun_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '002A', time_start=time_block_start)\n",
    "comp_time_data.update({'2A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 002B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "infile = op.join(qspace.DataOutput_dir, '002A-ALL_mapped_PDBS.csv')\n",
    "allMappedPDBs_PDBinfo = pd.read_csv(infile,index_col=0)  \n",
    "allMappedPDBs_PDBinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "pdbModule.run_002B_downloadPDBs(allMappedPDBs_PDBinfo.pdb_entry.unique(),\n",
    "                               force_download  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbioassembly = pdbModule.run_002B_downloadPDB_bioassemblies(dfpdb_mapped= allMappedPDBs_PDBinfo ,\n",
    "                                                             force_download = False,\n",
    "                                                             outfolder = qspace.bioassemblyStructuresDir,\n",
    "                                                             use_existing_data = not force_rerun_global\n",
    "                                                            )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '002B', time_start=time_block_start)\n",
    "comp_time_data.update({'2B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fig. S6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### \n",
    "infile = op.join(qspace.DataOutput_dir, '002A-ALL_mapped_PDBS.csv')\n",
    "allMappedPDBs_PDBinfo = pd.read_csv(infile,index_col=0)  \n",
    "########### \n",
    "infile = op.join(qspace.DataOutput_dir,'002A-uniprot_to_pdb.csv') \n",
    "textService_UniToPDB = pd.read_csv(infile)\n",
    "########### \n",
    "infile = op.join(qspace.DataOutput_dir,'002A-uniprot_to_pdb_full_info.csv') \n",
    "textService_PDBinfo = pd.read_csv(infile)\n",
    "########### \n",
    "query_type = \"UniProt\"\n",
    "json_file = op.join(qspace.DataOutput_dir,'002A-BLAST_PDB_{}Seq.json'.format(query_type)) \n",
    "if op.exists(json_file):\n",
    "    with open(json_file, 'rb') as f:\n",
    "        sequenceService_UniProt = json.load(f)\n",
    "    sequenceService_UniProt = ast.literal_eval(sequenceService_UniProt)\n",
    "########### \n",
    "query_type = \"Alleleome\"\n",
    "json_file = op.join(qspace.DataOutput_dir,'002A-BLAST_PDB_{}Seq.json'.format(query_type)) \n",
    "if op.exists(json_file):\n",
    "    with open(json_file, 'rb') as f:\n",
    "        sequenceService_Alleleome = json.load(f)\n",
    "    sequenceService_Alleleome = ast.literal_eval(sequenceService_Alleleome)\n",
    "\n",
    "########### df bioassembly\n",
    "infile = op.join(qspace.DataOutput_dir,'002B-ALL_mapped_BIOASSEMBLY.csv') \n",
    "dfbioassembly = pd.read_csv(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax =plt.subplots()\n",
    "fig.set_figheight(10) \n",
    "fig.set_figwidth(10)\n",
    "gs1 = gridspec.GridSpec(2,2 ,height_ratios= [1.5,1], width_ratios=[1,1])\n",
    "gs1.update( wspace=0.25, hspace = 0.1)\n",
    "ax1 = plt.subplot(gs1[0,0])\n",
    "ax2 = plt.subplot(gs1[0,1])\n",
    "ax3 = plt.subplot(gs1[1,0])\n",
    "ax4 = plt.subplot(gs1[1,1])\n",
    "\n",
    "data = [textService_UniToPDB, textService_PDBinfo, sequenceService_UniProt, sequenceService_Alleleome]\n",
    "figuresModule.figS6_AB(data, query ='genes',fig = fig , ax = ax1,save = False)\n",
    "figuresModule.figS6_AB(data, query ='structures',fig = fig, ax = ax2,save = False)\n",
    "figuresModule.figS6_C(dfbioassembly,fig = fig, ax = ax3,save = False)\n",
    "figuresModule.figS6_D(dfbioassembly,fig = fig, ax = ax4,save = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 002C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### \n",
    "infile = op.join(qspace.DataOutput_dir, '002A-ALL_mapped_PDBS.csv')\n",
    "allMappedPDBs_PDBinfo = pd.read_csv(infile,index_col=0)  \n",
    "########### \n",
    "infile = op.join(qspace.DataOutput_dir,'002A-uniprot_to_pdb.csv') \n",
    "textService_UniToPDB = pd.read_csv(infile)\n",
    "########### \n",
    "infile = op.join(qspace.DataOutput_dir,'002A-uniprot_to_pdb_full_info.csv') \n",
    "textService_PDBinfo = pd.read_csv(infile)\n",
    "########### \n",
    "query_type = \"UniProt\"\n",
    "json_file = op.join(qspace.DataOutput_dir,'002A-BLAST_PDB_{}Seq.json'.format(query_type)) \n",
    "if op.exists(json_file):\n",
    "    with open(json_file, 'rb') as f:\n",
    "        sequenceService_UniProt = json.load(f)\n",
    "    sequenceService_UniProt = ast.literal_eval(sequenceService_UniProt)\n",
    "########### \n",
    "query_type = \"Alleleome\"\n",
    "json_file = op.join(qspace.DataOutput_dir,'002A-BLAST_PDB_{}Seq.json'.format(query_type)) \n",
    "if op.exists(json_file):\n",
    "    with open(json_file, 'rb') as f:\n",
    "        sequenceService_Alleleome = json.load(f)\n",
    "    sequenceService_Alleleome = ast.literal_eval(sequenceService_Alleleome)\n",
    "\n",
    "########### df bioassembly\n",
    "infile = op.join(qspace.DataOutput_dir,'002B-ALL_mapped_BIOASSEMBLY.csv') \n",
    "dfbioassembly = pd.read_csv(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "pdbMaps,bioMaps= pdbModule.run_002C_mapAPI_DataToBioassemblies(sequenceService_api_result= sequenceService_UniProt,\n",
    "                                                                dfpdb_mapped = allMappedPDBs_PDBinfo,\n",
    "                                                                dfbioassembly = dfbioassembly,\n",
    "                                                                query_type = 'Uniprot',\n",
    "                                                                chain_source = 'auth_asym_ids')\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '002C', time_start=time_block_start)\n",
    "comp_time_data.update({'2C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 002D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(op.join(qspace.DataOutput_dir, \"000A-uniprot_blattner_mapping.json\"), 'rb') as f:\n",
    "    blattnerUniprotMapping = json.load(f)\n",
    "dfseq = op.join(qspace.DataOutput_dir, '001D-dfrepseq.csv')\n",
    "dfseq = pd.read_csv(dfseq, index_col=0)\n",
    "\n",
    "\n",
    "########### \n",
    "json_file = op.join(qspace.DataOutput_dir,'002C-Uniprot-PDB_quality.json') \n",
    "if op.exists(json_file):\n",
    "    with open(json_file, 'rb') as f:\n",
    "        pdbMaps = json.load(f)\n",
    "#     sequenceService_UniProt = ast.literal_eval(sequenceService_UniProt)\n",
    "########### \n",
    "json_file = op.join(qspace.DataOutput_dir,'002C-Uniprot-BIO_quality.json') \n",
    "if op.exists(json_file):\n",
    "    with open(json_file, 'rb') as f:\n",
    "        bioMaps = json.load(f)\n",
    "#     sequenceService_UniProt = ast.literal_eval(sequenceService_UniProt)\n",
    "\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '002A-PDBstructureInfo.csv')\n",
    "dfpdb_structure_info = pd.read_csv(infile,index_col=0)  \n",
    "dfpdb_structure_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dfpseudo_pdb, dfpseudo_pdb_best = pdbModule.run_002D_pseudo_structures(bioMaps=bioMaps,\n",
    "                                                                       dfrepseq = dfseq,\n",
    "                                                                       query_type = 'PDB',\n",
    "                                                                       dfpdb_structure_info = dfpdb_structure_info)\n",
    "pdb_download_errors = pdbModule.run_002D_downloadPDBfiles(dfpseudo_pdb_best,\n",
    "                                                          pdb_folder = qspace.pdbStructuresDir,\n",
    "                                                          force_rerun = force_rerun_global,\n",
    "                                                          download_errors = []\n",
    "                                                         )\n",
    "dfStructureSeqs = pdbModule.run_002D_getAASeqInPDBFile(dfpseudo_pdb_best,                               \n",
    "                                                       force_rerun = force_rerun_global)\n",
    "\n",
    "dfpseudo_pdb_best_needle = pdbModule.run_002D_needle_alignment_quality(dfbest=dfpseudo_pdb_best,\n",
    "                                                           dfStructureSeqs_all=dfStructureSeqs,\n",
    "                                                           dfrepseq = dfseq,\n",
    "                                                           needle_dir = qspace.SequenceAlignmentDir,\n",
    "                                                           checked = [],\n",
    "                                                           force_rerun =  force_rerun_global\n",
    "                                                          )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '002D', time_start=time_block_start)\n",
    "comp_time_data.update({'2D' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fig. S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpseudo_swiss        = pd.read_csv(op.join(qspace.DataOutput_dir,'001F-all_structures_SWISS.csv'), index_col=0)\n",
    "dfpseudo_swiss_best   = pd.read_csv(op.join(qspace.DataOutput_dir,'001F-best_structures_SWISS.csv'), index_col=0)\n",
    "dfpseudo_itasser      = pd.read_csv(op.join(qspace.DataOutput_dir,'001F-all_structures_ITASSER.csv'), index_col=0)\n",
    "dfpseudo_itasser_best = pd.read_csv(op.join(qspace.DataOutput_dir,'001F-best_structures_ITASSER.csv'), index_col=0)\n",
    "dfpseudo_alphafold    = pd.read_csv(op.join(qspace.DataOutput_dir,'001F-all_structures_ALPHAFOLD.csv'), index_col=0)\n",
    "\n",
    "dfpseudo_pdb                = pd.read_csv(op.join(qspace.DataOutput_dir,'002D-all_structures_PDB.csv'), index_col=0)\n",
    "dfpseudo_pdb_best_needle    = pd.read_csv(op.join(qspace.DataOutput_dir,'002D-best_structures_PDB.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genes_from_dfpseudo(dfpseudo):\n",
    "    genes_covered = []\n",
    "    for gs in dfpseudo.gene_stoichiometry.values:\n",
    "        if type(gs) == str:\n",
    "            gs = ast.literal_eval(gs)\n",
    "        genes_covered += gs.keys()\n",
    "    return set(genes_covered)\n",
    "\n",
    "fig,ax =plt.subplots()\n",
    "fig.set_figheight(10) \n",
    "fig.set_figwidth(10)\n",
    "gs1 = gridspec.GridSpec(3,3 ,height_ratios= [1,1,1.75], width_ratios=[1,1,1.75])\n",
    "gs1.update( wspace=0.35, hspace = 0.2)\n",
    "ax1 = plt.subplot(gs1[0:2,0:2])\n",
    "ax2 = plt.subplot(gs1[0,2])\n",
    "ax3 = plt.subplot(gs1[1,2])\n",
    "ax4 = plt.subplot(gs1[2,0])\n",
    "ax5 = plt.subplot(gs1[2,1])\n",
    "ax6 = plt.subplot(gs1[2,2])\n",
    "\n",
    "\n",
    "genes_swiss = get_genes_from_dfpseudo(dfpseudo_swiss)\n",
    "genes_pdb = get_genes_from_dfpseudo(dfpseudo_pdb)\n",
    "genes_itasser = get_genes_from_dfpseudo(dfpseudo_itasser)\n",
    "genes_alphafold = get_genes_from_dfpseudo(dfpseudo_alphafold)\n",
    "data = [genes_swiss,genes_pdb,genes_itasser,genes_alphafold]\n",
    "figuresModule.figS7_A(data,fig = fig, ax = ax1, save = False)\n",
    "\n",
    "figuresModule.figS7_BCDE(dfpseudo= dfpseudo_itasser,fig = fig, ax = ax2,save = False, legend = True, query = 'ITASSER')\n",
    "figuresModule.figS7_BCDE(dfpseudo= dfpseudo_swiss,fig = fig, ax = ax4,save = False, legend = True, query = 'SWISS')\n",
    "figuresModule.figS7_BCDE(dfpseudo= dfpseudo_pdb,fig = fig, ax = ax5,save = False, legend = True, query = 'PDB')\n",
    "figuresModule.figS7_BCDE(dfpseudo= dfpseudo_alphafold,fig = fig, ax = ax3,save = False, legend = True, query = 'ALPHAFOLD')\n",
    "\n",
    "data = {\"ITASSER\" : dfpseudo_itasser_best,\n",
    "        \"SWISS\" : dfpseudo_swiss_best,\n",
    "        \"PDB\" : dfpseudo_pdb_best_needle,\n",
    "        \"ALPHAFOLD\" : dfpseudo_alphafold,}\n",
    "\n",
    "figuresModule.figS7_F(data,fig = fig, ax = ax6, save = False, legend = True, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'PDB Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein-Target-Annotation Module (#003A-D)\n",
    "- <b>#003A</b> --  Find annotated proteins and oligomerization states\n",
    "- <b>#003B</b> --  Structure-guided re-annotation of monomers w/structural evidence of oligomerization\n",
    "- <b>#003C</b> --  Prep large oligomers for de novo structure generation with Alphafold Multimer\n",
    "- <b>#003D</b> --  QCQA Alphafold Multimer models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inputs needed to run 003A-D ####\n",
    "\n",
    "infile = op.join(qspace.Input_dir, '003A-enzyme_targets_ecocyc.csv')\n",
    "proteinAnnot_ecocyc_input = pd.read_csv(infile, index_col=0,engine='python')\n",
    "\n",
    "infile = op.join(qspace.Input_dir, '003A-enzyme_targets_cobraME.json')\n",
    "with open(infile ,'r') as f:\n",
    "    proteinAnnot_cobraME_input = json.load(f)\n",
    "    \n",
    "#### Inputs needed to run 003A-D ####\n",
    "dfseq = op.join(qspace.DataOutput_dir, '001D-dfrepseq.csv')\n",
    "dfseq = pd.read_csv(dfseq, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 003A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "proteinAnnot_ecocyc,genes_ecocyc= pTAM.run_003A_get_protein_annotations_ecocyc(proteinAnnot_ecocyc_input, queryGeneList=qspacegeneList)\n",
    "# proteinAnnot_ecocyc,genes_ecocyc =filter_cplx_for_genes_not_in_query(proteinAnnotation=proteinAnnot_ecocyc,)\n",
    "\n",
    "proteinAnnot_cobrame,genes_cobrame= pTAM.run_003A_get_protein_annotations_cobrame(proteinAnnot_cobraME_input,queryGeneList=qspacegeneList)\n",
    "# proteinAnnot_cobrame,genes_cobrame =filter_cplx_for_genes_not_in_query(proteinAnnotation=proteinAnnot_cobrame, queryGeneList=qspacegeneList)\n",
    "\n",
    "genes_found = genes_ecocyc.union(genes_cobrame)\n",
    "proteinAnnot_unmodeled,genes_unmodeled= pTAM.run_003A_get_protein_annotations_unmodeled(dfrepseq = dfseq, \n",
    "                                                                                        genes_covered=genes_found)\n",
    "\n",
    "proteinTargets, proteinTargetsMissing, genesMissing = pTAM.run_003A_get_protein_annotations_final(proteinAnnotations_ecocyc=proteinAnnot_ecocyc,\n",
    "                                                                                                  proteinAnnotations_cobrame=proteinAnnot_cobrame,\n",
    "                                                                                                  proteinAnnotations_unmodeled=proteinAnnot_unmodeled,\n",
    "                                                                                                  dfrepseq=dfseq\n",
    "                                                                                                 )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point =get_computation_time(label = '003A', time_start=time_block_start)\n",
    "comp_time_data.update({'3A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)\n",
    "proteinTargets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 003B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "#import the best pseudo structures\n",
    "#PDB\n",
    "dfpdb_structures = pd.read_csv(op.join(qspace.DataOutput_dir,'002D-best_structures_PDB.csv'),index_col=0)\n",
    "#SWISS\n",
    "dfswiss_structures = pd.read_csv(op.join(qspace.DataOutput_dir,'001F-best_structures_SWISS.csv'),index_col=0)\n",
    "\n",
    "def ensure_ast(df, column_list):\n",
    "    for col in column_list:\n",
    "        changeDict = df.get(col).to_dict()\n",
    "        for k, v in changeDict.items():\n",
    "            if type(v) == str:\n",
    "                v = ast.literal_eval(v)\n",
    "            changeDict.update({k : v})\n",
    "        df[col] = pd.Series(changeDict) \n",
    "    return df\n",
    "\n",
    "dfpdb_structures = ensure_ast(dfpdb_structures, column_list= ['gene_stoichiometry','pdb_quality_needle','identical_structures'])\n",
    "dfpdb_structures['pdb_quality'] = dfpdb_structures['pdb_quality_needle'] \n",
    "dfswiss_structures = ensure_ast(dfswiss_structures, column_list= ['gene_stoichiometry','pdb_quality','identical_structures'])\n",
    "\n",
    "##### get combinind PDB/SWISS STRUCTURES\n",
    "appender_index = []\n",
    "appender = list(dfpdb_structures.drop(['pdb_quality_needle','pdb_entry'], axis = 1).to_records(index=False))\n",
    "appender_index += dfpdb_structures.index.tolist()\n",
    "\n",
    "appender2 = list(dfswiss_structures.to_records(index=False))\n",
    "appender_index += dfswiss_structures.index.tolist()\n",
    "print (len(appender), len(appender2))\n",
    "\n",
    "appender += appender2\n",
    "print (len(appender))\n",
    "dfpdb_and_swiss_structures = pd.DataFrame.from_records(appender, index = appender_index, columns=dfpdb_structures.drop(['pdb_quality_needle','pdb_entry'], axis = 1).columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Structural Evidence used to re-annotate protein complexes\n",
    "new_recipes = {}\n",
    "df_recipes_changed = pd.DataFrame(columns= ['finalGeneStoich', 'stoichChanged',\n",
    "                                            'method', 'caseNum', 'evidenceSupported',\n",
    "                                            'evidenceIgnored'])\n",
    "\n",
    "\n",
    "results_pdb= pTAM.run_003B_monomers(proteinTargets,\n",
    "                                    df_structures=dfpdb_structures,\n",
    "                                    query = 'PDB'\n",
    "                                   )\n",
    "[df_pdb, stoich_pdb, quality_pdb, output_pdb, to_bfs_pdb, full_pdb, homo_oligo_pdb, hetero_oligo_pdb,monomerAnnot ] = results_pdb\n",
    "results_swiss= pTAM.run_003B_monomers(proteinTargets,\n",
    "                                    df_structures=dfswiss_structures,\n",
    "                                    query = 'SWISS'\n",
    "                                   )\n",
    "[df_swiss, stoich_swiss, quality_swiss, output_swiss, to_bfs_swiss, full_swiss, homo_oligo_swiss, hetero_oligo_swiss,monomerAnnot ] = results_swiss\n",
    "\n",
    "structuralEvidence = {\"hetero_pdb\":hetero_oligo_pdb,\n",
    "                      \"homo_pdb\":homo_oligo_pdb,\n",
    "                      \"homo_swiss\":homo_oligo_swiss,\n",
    "                      'full_pdb':full_pdb,\n",
    "                     'full_swiss':full_swiss}\n",
    "\n",
    "df_hetero_oligo = pTAM.run_003B_HeteroOligos(structuralEvidence= structuralEvidence,\n",
    "                                             monomer_parent=monomerAnnot,\n",
    "                                             quality_pdb=quality_pdb,\n",
    "                                             blast_cutoff = 80)\n",
    "\n",
    "\n",
    "\n",
    "new_recipes, df_recipes_changed = pTAM.run_003B_caseV_HeteroOligos(dfpdb_and_swiss_structures,\n",
    "                                                                    curation_confirmed = True,\n",
    "                                                                    monomer_parent = monomerAnnot,\n",
    "                                                                   new_recipes=new_recipes,\n",
    "                                                                   df_recipes_changed=df_recipes_changed,\n",
    "                                                                   \n",
    "                                                              )\n",
    "new_recipes, df_recipes_changed = pTAM.run_003B_caseII_autoQCQA_SwissHomoOligos(structuralEvidence=structuralEvidence,\n",
    "                                                                         df_swiss = df_swiss,\n",
    "                                                                         real_structure_stoich_swiss = stoich_swiss,\n",
    "                                                                         dfpdb_and_swiss_structures=dfpdb_and_swiss_structures,\n",
    "                                                                         new_recipes = new_recipes,    \n",
    "                                                                         df_recipes_changed = df_recipes_changed,\n",
    "                                                                         monomer_parent = monomerAnnot,\n",
    "                                                                                proteinAnnotation= proteinTargets,\n",
    "                                                                        )\n",
    "df_homo_pdb = pTAM.run_003B_caseIV_run_HomoOligos(structuralEvidence,\n",
    "                                           monomer_parent = monomerAnnot,\n",
    "                                           dfpdb_structures=df_pdb,\n",
    "                              )\n",
    "new_recipes,df_recipes_changed = pTAM.run_003B_caseIV_handle_HomoOligos(dfpdb_and_swiss_structures = dfpdb_and_swiss_structures,\n",
    "                                 new_recipes = new_recipes,    \n",
    "                                 df_recipes_changed = df_recipes_changed,\n",
    "                                 curation_confirmed = True,\n",
    "                                 monomer_parent = monomerAnnot,\n",
    "                                )\n",
    "new_recipes,df_recipes_changed = pTAM.run_003B_caseI_homoOligos_PDB_and_SWISS(structuralEvidence=structuralEvidence,\n",
    "                                                                        df_swiss = df_swiss,\n",
    "                                                                        df_pdb= df_pdb,\n",
    "                                                                        dfpdb_and_swiss_structures=dfpdb_and_swiss_structures,\n",
    "                                                                        real_structure_stoich_swiss = stoich_swiss ,\n",
    "                                                                        oldProteinAnnotation = proteinTargets ,\n",
    "                                                                        monomer_parent= monomerAnnot,\n",
    "                                                                        new_recipes = new_recipes,\n",
    "                                                                        df_recipes_changed =df_recipes_changed\n",
    "                                                                       )\n",
    "new_recipes,df_recipes_changed = pTAM.run_003B_caseIII_handle_HomoOligos_PDB_and_SWISS(new_recipes = new_recipes,\n",
    "                                                                               df_recipes_changed = df_recipes_changed,\n",
    "                                                                               curation_confirmed = True,\n",
    "                                                                               monomer_parent = monomerAnnot,\n",
    "                                                                               \n",
    "                                                                              )\n",
    "df_recipes_changed['evidenceSupported'] =df_recipes_changed['evidenceQuality']\n",
    "df_recipes_changed = df_recipes_changed.drop('evidenceQuality', axis = 1)\n",
    "outfile = op.join(qspace.DataOutput_dir, '003B-supplement-enzyme_stoichs_changed.csv')\n",
    "df_recipes_changed.to_csv(outfile)\n",
    "# print \"Saving....\\n\\t> {}\".format(outfile)\n",
    "\n",
    "new_data,translation,proteinTargetsNew = pTAM.run_003B_rename_enzymes(new_recipes,\n",
    "                                                                      dfparent= proteinTargets,\n",
    "                                                                      dfrepseq = dfseq)\n",
    "\n",
    "oligomer_parent= proteinTargetsNew[proteinTargetsNew.k_mer.isin([1,'1']) == False]\n",
    "\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '003B', time_start=time_block_start)\n",
    "comp_time_data.update({'3B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Fig S8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figuresModule.figS8_A(proteinTargets,fig = False, ax = False, save = False)\n",
    "figuresModule.figS8_B(proteinTargets,fig = False, ax = False, save = False)\n",
    "figuresModule.figS8_C(hetero_oligo_pdb, homo_oligo_pdb,homo_oligo_swiss,fig = False, ax = False, save = False)\n",
    "figuresModule.figS8_D(df_recipes_changed,fig = False, ax = False, save = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 003C"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#import the best pseudo structures\n",
    "#PDB\n",
    "dfpdb_structures = pd.read_csv('data/002D-best_structures_PDB.csv',index_col=0)\n",
    "#SWISS\n",
    "dfswiss_structures = pd.read_csv('data/001F-best_structures_SWISS.csv',index_col=0)\n",
    "\n",
    "def ensure_ast(df, column_list):\n",
    "    for col in column_list:\n",
    "        changeDict = df.get(col).to_dict()\n",
    "        for k, v in changeDict.items():\n",
    "            if type(v) == str:\n",
    "                v = ast.literal_eval(v)\n",
    "            changeDict.update({k : v})\n",
    "        df[col] = pd.Series(changeDict) \n",
    "    return df\n",
    "\n",
    "dfpdb_structures = ensure_ast(dfpdb_structures, column_list= ['gene_stoichiometry','pdb_quality_needle','identical_structures'])\n",
    "dfpdb_structures['pdb_quality'] = dfpdb_structures['pdb_quality_needle'] \n",
    "dfswiss_structures = ensure_ast(dfswiss_structures, column_list= ['gene_stoichiometry','pdb_quality','identical_structures'])\n",
    "\n",
    "##### get combinind PDB/SWISS STRUCTURES\n",
    "appender_index = []\n",
    "appender = list(dfpdb_structures.drop(['pdb_quality_needle','pdb_entry'], axis = 1).to_records(index=False))\n",
    "appender_index += dfpdb_structures.index.tolist()\n",
    "\n",
    "appender2 = list(dfswiss_structures.to_records(index=False))\n",
    "appender_index += dfswiss_structures.index.tolist()\n",
    "print (len(appender), len(appender2),)\n",
    "\n",
    "appender += appender2\n",
    "print (len(appender))\n",
    "dfpdb_and_swiss_structures = pd.DataFrame.from_records(appender, index = appender_index, columns=dfpdb_structures.drop(['pdb_quality_needle','pdb_entry'], axis = 1).columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = op.join(qspace.DataOutput_dir,'003A-enzyme_targets_prior_to_BFS.csv')\n",
    "proteinTargetsOld = pd.read_csv(infile,index_col=0)\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir,'003B-enzyme_targets_with_new_oligomers.csv')\n",
    "proteinTargetsNew = pd.read_csv(infile,index_col=0)\n",
    "\n",
    "enzymes = proteinTargetsOld[proteinTargetsOld.k_mer > 1]\n",
    "print (\"OLD Number of Multimeric Enzymes : \", len(enzymes))\n",
    "\n",
    "enzymes = proteinTargetsNew[proteinTargetsNew.k_mer > 1]\n",
    "print (\"NEW Number of Multimeric Enzymes : \", len(enzymes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligomer_parent= proteinTargetsNew[proteinTargetsNew.k_mer.isin([1,'1']) == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "results_pdb= pTAM.run_003C_oliogmers(oligomer_parent,\n",
    "                                    df_structures=dfpdb_structures,\n",
    "                                    query = 'PDB'\n",
    "                                   )\n",
    "[df_pdb, stoich_pdb, quality_pdb, output_pdb, to_bfs_pdb, full_pdb, homo_oligo_pdb, hetero_oligo_pdb,oligomerAnnot ] = results_pdb\n",
    "results_swiss= pTAM.run_003C_oliogmers(oligomer_parent,\n",
    "                                    df_structures=dfswiss_structures,\n",
    "                                    query = 'SWISS'\n",
    "                                   )\n",
    "[df_swiss, stoich_swiss, quality_swiss, output_swiss, to_bfs_swiss, full_swiss, homo_oligo_swiss, hetero_oligo_swiss,oligomerAnnot] = results_swiss\n",
    "\n",
    "structuralEvidence = {\"hetero_pdb\":hetero_oligo_pdb,\n",
    "                      \"homo_pdb\":homo_oligo_pdb,\n",
    "                      \"homo_swiss\":homo_oligo_swiss,\n",
    "                      'full_pdb':full_pdb,\n",
    "                     'full_swiss':full_swiss}\n",
    "\n",
    "dfOligomerMissing = pTAM.run_003C_find_missing_oligos(structuralEvidence =structuralEvidence ,\n",
    "                                                      oligomer_parent=oligomer_parent,\n",
    "                                                      dfpdb_and_swiss_structures=dfpdb_and_swiss_structures,\n",
    "                                                      df_swiss=df_swiss\n",
    "                                                     )\n",
    "sent_to_AFmultimer = pTAM.run_003C_sendCplxSeqs_to_AFMultiFolder(df_oligo_missing=dfOligomerMissing, \n",
    "                                                                 outdir = qspace.AlphaMultiSeqDir,\n",
    "                                                                 alphafold_seq_len_cutoff = 2000,\n",
    "                                                                 remove_old_seqs= True,\n",
    "                                                                )\n",
    "\n",
    "sent_to_AFmultimer_byParts = pTAM.run_003C_sendByPartsSeqs_to_AFMultiFolder(df_oligo_missing=dfOligomerMissing, \n",
    "                                                                    dfrepseq=dfseq,\n",
    "                                                                    outdir = qspace.AlphaMultiSeqDir,\n",
    "                                                                    alphafold_seq_len_cutoff = 2000,\n",
    "                                                                    remove_old_seqs= False,\n",
    "                                                                   )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '003C', time_start=time_block_start)\n",
    "comp_time_data.update({'3C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "queryAF = sent_to_AFmultimer.index.tolist() + sent_to_AFmultimer_byParts.index.tolist()\n",
    "\n",
    "dfalphamulti, AFchain_quality_dict,AFchain_geneStoich_dict = pTAM.run_003D_autoQCQA_AFMultimerModels(queryAF=queryAF,\n",
    "                                                                             dfseq = dfseq,\n",
    "                                                                             alphaFoldMultimer_dir = qspace.alphafoldMultimerDir,\n",
    "                                                                            )\n",
    "\n",
    "dfalphamulti_curated = pTAM.run_003D_loadManualQCQA_AFMultimerModels(queryAF)\n",
    "\n",
    "dfpseudo_alphaMulti_best = pTAM.run_003D_pseudoStructures_AF_best(dfalpha=dfalphamulti_curated,\n",
    "                                                     geneStoich_dict= AFchain_geneStoich_dict,\n",
    "                                                     quality_dict  = AFchain_quality_dict\n",
    "                                                    )   \n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '003D', time_start=time_block_start)\n",
    "comp_time_data.update({'3D' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figuresModule.figS9_A(dfalphamulti_curated,fig = False, ax = False, save = False)\n",
    "figuresModule.figS9_B(dfalphamulti_curated,fig = False, ax = False, save = False)\n",
    "figuresModule.figS9_C(dfalphamulti_curated,fig = False, ax = False, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Protein Target Annotation Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protein-To-Structures Module (#004A-C)\n",
    "- <b>#004A</b> --  Match Structures to Protein Complexes, tradeoff in multi-structure vs single-structure matches\n",
    "- <b>#004B</b> --  Build the quaternary structural proteome dataframe using sequence alignments\n",
    "- <b>#004C</b> --  Ensure that chains in the structure files (.cif, .pdb, bioassembly.pdb, .etc) and chains in the PDB search APIs (.cifs) are consisent\n",
    "<!-- - <b>#003D</b> --  QCQA Alphafold Multimer models  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Inputs Needed to Run #004A-C\n",
    "# dfseq = op.join(qspace.DataOutputDir, '001D-dfrepseq.csv')\n",
    "# dfseq = pd.read_csv(dfseq, index_col=0)\n",
    "\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '003A-enzyme_targets_prior_to_BFS.csv')\n",
    "proteinTargets = pd.read_csv(infile, index_col=0)\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '003B-enzyme_targets_with_new_oligomers.csv')\n",
    "proteinTargetsNew = pd.read_csv(infile, index_col=0)\n",
    "\n",
    "enzymes = proteinTargets[proteinTargets.k_mer > 1]\n",
    "print( \"Number of Multimeric Enzymes (Old): \", len(enzymes))\n",
    "\n",
    "enzymes = proteinTargetsNew[proteinTargetsNew.k_mer > 1]\n",
    "print (\"Number of Multimeric Enzymes (New): \", len(enzymes))\n",
    "\n",
    "\n",
    "#PDB\n",
    "infile = op.join(qspace.DataOutput_dir, '002D-best_structures_PDB.csv')\n",
    "dfpseudo_pdb_best_needle = pd.read_csv(infile,index_col=0)\n",
    "dfpseudo_pdb_best_needle['pdb_quality'] = pd.Series(dfpseudo_pdb_best_needle['pdb_quality_needle'])\n",
    "# SWISS\n",
    "infile = op.join(qspace.DataOutput_dir, '001F-best_structures_SWISS.csv')\n",
    "dfpseudo_swiss_best = pd.read_csv(infile,index_col=0)\n",
    "\n",
    "# ITASSER\n",
    "infile = op.join(qspace.DataOutput_dir, '001F-best_structures_ITASSER.csv')\n",
    "dfpseudo_itasser_best = pd.read_csv(infile,index_col=0)\n",
    "\n",
    "# Alphafold\n",
    "infile = op.join(qspace.DataOutput_dir, '001F-best_structures_ALPHAFOLD.csv')\n",
    "dfpseudo_alphafold_best = pd.read_csv(infile,index_col=0)\n",
    "\n",
    "# Alphafold Multimer\n",
    "infile = op.join(qspace.DataOutput_dir, '003D-best_structures_AlphafoldMultimer.csv')\n",
    "dfpseudo_alphaMulti_best = pd.read_csv(infile,index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 004A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dfbest = pd.DataFrame()\n",
    "dfbest = dfbest.append(dfpseudo_pdb_best_needle)\n",
    "dfbest = dfbest.append(dfpseudo_swiss_best)\n",
    "dfbest = dfbest.append(dfpseudo_itasser_best)\n",
    "dfbest = dfbest.append(dfpseudo_alphafold_best)\n",
    "dfbest = dfbest.append(dfpseudo_alphaMulti_best)\n",
    "outfile = op.join(qspace.DataOutput_dir, '003D-best_structures_ALL.csv')\n",
    "dfbest.to_csv(outfile)                     \n",
    "print ('Saving...\\n\\t> {}'.format(outfile))\n",
    "\n",
    "quality_cutoff  = {'PDB': 70,'SWISS': 70,'ITASSER': 70,'ALPHAFOLD': 70, 'ALPHAFOLD_MULTIMER' : 0} #multimer results already checked,\n",
    "\n",
    "data = pTSM.run_004A_get_matches(dfbest,\n",
    "                                 proteinTargetsNew=proteinTargetsNew,\n",
    "                                 quality_cutoff=quality_cutoff,\n",
    "                                 remove_bad_structures = False,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs_answers = pTSM.manual_bfs_answers\n",
    "bfs_answers = pTSM.run_004A_MultiStructureMatching(to_bfs_filtered=data['BFSRequired'],\n",
    "                                                   proteinTargetsNew=proteinTargetsNew,\n",
    "                                                   dfbest=dfbest,\n",
    "                                                   test_pyr  = True,\n",
    "                                                   test_ribo = True,\n",
    "                                                   bfs_answers = bfs_answers,\n",
    "                                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmatch = pTSM.run_004A_GatherMatches(bfs_answers = bfs_answers,\n",
    "                                      full_1_1 = data['FullMatch'],\n",
    "                                      dfparent = proteinTargetsNew,\n",
    "                                      dfbest = dfbest,\n",
    "                                     )\n",
    "\n",
    "dfmatch = pTSM.run_004A_rankMatches(dfmatch)\n",
    "\n",
    "dfmatch_best = pTSM.run_004A_chooseBestMatch(dfmatch)\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '004A', time_start=time_block_start)\n",
    "comp_time_data.update({'4A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figuresModule.figS2(dfmatch_best,fig = False, ax = False, save = False)\n",
    "figuresModule.fig2_B(dfmatch_best)\n",
    "figuresModule.fig2_C(dfqual = dfmatch_best,\n",
    "                    proteinTargetsOld = proteinTargets,\n",
    "                    proteinTargetsNew = proteinTargetsNew,\n",
    "                    )\n",
    "figuresModule.fig2_D(dfqual = dfmatch_best,\n",
    "                    proteinTargetsNew = proteinTargetsNew,\n",
    "                    )\n",
    "figuresModule.figS10_A(data)\n",
    "\n",
    "\n",
    "dfmatch_for_supp = dfmatch[dfmatch.cplx.isin(bfs_answers)]\n",
    "dfqual_for_supp = dfmatch_best[dfmatch_best.index.isin(bfs_answers)]\n",
    "figuresModule.figS10_BE(dfmatch_for_supp=dfmatch_for_supp,dfqual_for_supp=dfqual_for_supp, save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 004B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "dfmatch_best = pd.read_csv(op.join(qspace.DataOutput_dir,'004A-BFS_best_match_for_protein_complexes.csv'),index_col=0)\n",
    "dfbest = pd.read_csv(op.join(qspace.DataOutput_dir,'003D-best_structures_ALL.csv'),index_col=0)\n",
    "dfseq = pd.read_csv(op.join(qspace.DataOutput_dir,'001D-dfrepseq.csv'),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dfQuatProteome = pTSM.run_004B_QuaternaryProteomeSkeleton(dfqual = dfmatch_best,\n",
    "                                                          dfbest = dfbest,\n",
    "                                                          dfrepseq = dfseq,\n",
    "                                                         )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '004B', time_start=time_block_start)\n",
    "comp_time_data.update({'4B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 004C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "infile = op.join(qspace.DataOutput_dir, '004B-alldata_skeleton.csv') \n",
    "dfQuatProteome = pd.read_csv(infile, index_col = 0)\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '002A-ALL_mapped_PDBS.csv') \n",
    "PDBchainSeqsAPI = pd.read_csv(infile,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "# missing_list = ['2vwt-assembly1','4dop-assembly1'] + dfQuatProteome.structureId.unique().tolist()[0:10]\n",
    "\n",
    "# errlist = ['3srt-assembly1','1v58-assembly1','1rc2-assembly1','2vyc-assembly1','5vj1-assembly3','2scu-assembly1',]\n",
    "\n",
    "dfallchains, dfallchains_w_seq,translation_dict= pTSM.run_004C_get_all_chains(dfalldata = dfQuatProteome,#[dfQuatProteome.structureId.isin(errlist)],\n",
    "                                                                PDBchainSeqsAPI=PDBchainSeqsAPI,\n",
    "                                                                force_rerun = force_rerun_global,\n",
    "                                                               )\n",
    "\n",
    "dfallchains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQuatProteome = pTSM.run_004C_global_chain_consistency(dfalldata=dfQuatProteome,\n",
    "                                                        dfallchains=dfallchains,\n",
    "                                                       )\n",
    "\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '004C', time_start=time_block_start)\n",
    "comp_time_data.update({'4C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fig 1E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "infile = op.join(qspace.DataOutput_dir, '004C-alldata_skeleton.csv')\n",
    "dfQuatProteome = pd.read_csv(infile, index_col=0)\n",
    "figuresModule.fig1_E(dfskeleton = dfQuatProteome)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fig 1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = op.join(qspace.DataOutput_dir, '004C-alldata_skeleton.csv')\n",
    "dfQuatProteome = pd.read_csv(infile, index_col=0)\n",
    "fig, ax =figuresModule.fig1_F(dfskeleton = dfQuatProteome)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Proteins to Structures Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membrane Module (#005A-F)\n",
    "- <b>#005A</b> --  Identify membrane structures from EcoCyc, GO, Uniprot, IML1515\n",
    "- <b>#005B</b> --  Write .pdb files for identified structures (to send to OPM)\n",
    "- <b>#005C</b> --  Run OPM server, download results\n",
    "- <b>#005D1</b> --  Calculate membrane planes from OPM\n",
    "- <b>#005D2</b> --  Calculate membrane planes from UniProt\n",
    "- <b>#005D3</b> --  Calculate membrane planes from DeepTMHMM\n",
    "- <b>#005E</b> --  QCQA membrane planes\n",
    "- <b>#005F</b> --  assign sub-cellular compartment with AA-level detail\n",
    "\n",
    "\n",
    "<!-- - <b>#003D</b> --  QCQA Alphafold Multimer models  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### inputs needed for membrane module\n",
    "dfseq = op.join(qspace.DataOutput_dir, '001D-dfrepseq.csv')\n",
    "dfseq = pd.read_csv(dfseq, index_col=0)\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '004C-alldata_skeleton.csv')\n",
    "dfQuatProteome = pd.read_csv(infile, index_col=0)\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '003D-best_structures_ALL.csv')\n",
    "dfbest_structures = pd.read_csv(infile, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 005A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs \n",
    "time_block_start = time.time()\n",
    "dfecocyc_loc = pd.read_csv(op.join(qspace.Input_dir, \"005A-EcocycSmartTable-All-genes-of-E.-coli-K-12-substr.-MG1655.txt\"),sep = '\\t')\n",
    "dfiml1515= pd.read_csv(op.join(qspace.Input_dir, \"005A-iML1515_GP_subsystems_nbt.3956-S7.csv\"))\n",
    "\n",
    "potentialMembraneStructures, potentialMembraneData = membraneModule.run_005A_IdentifyMembrane(dfrepseq = dfseq,\n",
    "                                                                             dfiml1515=dfiml1515,\n",
    "                                                                             dfall = dfQuatProteome[dfQuatProteome.sfileChain_Residue.isna() == False],\n",
    "                                                                             dfecocyc_loc = dfecocyc_loc,\n",
    "                                                                             uniprotSequenceDir = qspace.UniprotSeqsDir,\n",
    "                                                                            )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '005A', time_start=time_block_start)\n",
    "comp_time_data.update({'5A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)\n",
    "    \n",
    "with open (op.join(qspace.DataOutput_dir, \"005A_potentialMembraneStructuresAllSources.json\"),'w' ) as f:\n",
    "    json.dump(potentialMembraneData,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 005B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = op.join(qspace.DataOutput_dir, '005A-potential_membrane_structures.json')\n",
    "with open(infile, 'r') as f:\n",
    "    potentialMembraneStructures = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "structureFileLocations,opmChains = membraneModule.run_005B_writeOPMpdbs(potential_membrane_structures=potentialMembraneStructures,\n",
    "                                                                  outfolder = qspace.opmStructuresToSendDir,\n",
    "                                                                  force_rerun= True,\n",
    "                                                                 )\n",
    "sfileDict = structureFileLocations.sfile.to_dict()\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '005B', time_start=time_block_start)\n",
    "comp_time_data.update({'5B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 005C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorsOPM = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structureFileLocations = pd.read_csv(op.join(qspace.DataOutput_dir,'005B-opmStructureLocations.csv'),index_col = 0 )\n",
    "structureFileLocations.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works with selenium==3.14.0\n",
    "time_block_start = time.time()\n",
    "\n",
    "chromeDriverLocation = '/home/ecatoiu/Projects/chromedriver' \n",
    "\n",
    "\n",
    "errorsOPM,not_solved_dict = membraneModule.run_005C_opmServer(query_structureIds = structureFileLocations.index.tolist(),\n",
    "                                                              pdbOutputs = {},\n",
    "                                                              htmlOutputs = {},\n",
    "                                                              not_solved_dict = {},\n",
    "                                                              force_rerun = False,\n",
    "                                                              to_opm_PDBfolder = qspace.opmStructuresToSendDir ,\n",
    "                                                              from_opm_PDBfolder = qspace.opmOutputStructuresDir ,\n",
    "                                                              errorsOPM = [],\n",
    "                                                              chromeDriverLocation = chromeDriverLocation,\n",
    "                                                              OPMdataFolder = qspace.opmOutputDataDir,\n",
    "                                                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_solved_dict = {}\n",
    "\n",
    "while len(not_solved_dict) > 0:\n",
    "    not_solved_dict = membraneModule.run_005C_goBackandCheck(not_solved_dict,\n",
    "                                              to_opm_folder = qspace.opmStructuresToSendDir ,\n",
    "                                              from_opm_PDBfolder = qspace.opmOutputStructuresDir ,\n",
    "                                              force_rerun = False,\n",
    "                                              OPMdataFolder = qspace.opmOutputDataDir,\n",
    "                                              chromeDriverLocation = chromeDriverLocation,\n",
    "                                             )\n",
    "    time.sleep(30)\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '005C', time_start=time_block_start)\n",
    "comp_time_data.update({'5C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 005D1 - opm membrane calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "planes_dict, checked = membraneModule.run_005D1_opmPlanes(potential_membrane_structures=potentialMembraneStructures,\n",
    "                                                         OPMstructureFolder = qspace.opmOutputStructuresDir ,\n",
    "                                                         force_rerun = force_rerun_global,\n",
    "                                                         OPMJsonFolder = qspace.opmOutputDataDir,\n",
    "                                                         OPMcsvFolder = qspace.opmCsvDir,\n",
    "                                                         checked = []\n",
    "                                                        )\n",
    "dfmembrane_opm = membraneModule.run_005D1_membraneQCQA(planes_dict, query = 'OPM')\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '005D1', time_start=time_block_start)\n",
    "comp_time_data.update({'5D1' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 005D2 - uniprot membrane calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structureFileLocations = pd.read_csv(op.join(qspace.DataOutput_dir,'005B-opmStructureLocations.csv'),index_col = 0 )\n",
    "structureFileLocations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "potential_membrane_complex = dfQuatProteome[dfQuatProteome.structureId.isin(potentialMembraneStructures)].cplx.unique().tolist()\n",
    "\n",
    "dfmembrane_residues_uniprot = membraneModule.run_005D2_uniprotResidues(potential_membrane_structures=potentialMembraneStructures,\n",
    "                                                                     potential_membrane_complex=potential_membrane_complex,\n",
    "                                                                     dfalldata = dfQuatProteome,                                                                     \n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmembrane_residues_uniprot = membraneModule.fix_for_ecoli_proteome(dfmembrane_residues_uniprot)\n",
    "sfileDict = structureFileLocations.sfile.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes_dict = membraneModule.run_005D2_uniprotPlanes(dfmembrane_residues_uniprot=dfmembrane_residues_uniprot,\n",
    "                                                     sfileDict=sfileDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmembrane_uniprot = membraneModule.run_005D2_membraneQCQA(planes_dict=planes_dict, \n",
    "                                                           sfileDict=sfileDict,\n",
    "                                                           query = 'Uniprot', \n",
    "                                                           dfmembrane_residues_uniprot=dfmembrane_residues_uniprot,\n",
    "                                                           csvFolder =  qspace.UniprotCsvDir,\n",
    "                                                          )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '005D2', time_start=time_block_start)\n",
    "comp_time_data.update({'5D2' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 005D3 tmhmmm membrane calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "#inputs\n",
    "infile = op.join(qspace.DataOutput_dir, '005A-potential_membrane_structures.json')\n",
    "with open(infile, 'r') as f:\n",
    "    potentialMembraneStructures = json.load(f)\n",
    "    \n",
    "potential_membrane_complex = dfQuatProteome[dfQuatProteome.structureId.isin(potentialMembraneStructures)].cplx.unique().tolist()\n",
    "\n",
    "#run\n",
    "membraneModule.run_005D3_write_tmhmm_file(potential_membrane_complex= potential_membrane_complex,\n",
    "                                          dfalldata = dfQuatProteome,\n",
    "                                         force_rerun = force_rerun_global)\n",
    "\n",
    "dfmembrane_residues_tmhmm = membraneModule.run_005D3_tmhmmResidues(tmhmmFolder = qspace.tmhmmResultsDir,\n",
    "                                                                   dfalldata = dfQuatProteome)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "dfmembrane_residues_tmhmm = pd.read_csv(op.join(qspace.DataOutput_dir, '005D3-MembraneResiduesTMHMM.csv'),index_col=0)\n",
    "structureFileLocations = pd.read_csv(op.join(qspace.DataOutput_dir,'005B-opmStructureLocations.csv'),index_col = 0 )\n",
    "sfileDict = structureFileLocations.sfile.to_dict()\n",
    "\n",
    "#run\n",
    "planes_dict = membraneModule.run_005D3_tmhmmPlanes(dfmembrane_residues_tmhmm=dfmembrane_residues_tmhmm,\n",
    "                                                   sfileDict=sfileDict,\n",
    "                                                   dfalldata = dfQuatProteome,\n",
    "                                                  )\n",
    "\n",
    "dfmembrane_tmhmm = membraneModule.run_005D3_membraneQCQA(planes_dict=planes_dict, \n",
    "                                                         sfileDict=sfileDict,\n",
    "                                                         query = 'TMHMM', \n",
    "                                                         csvFolder =  qspace.TMHMMcsvDir,\n",
    "                                                         dfalldata = dfQuatProteome,\n",
    "                                                        )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point = get_computation_time(label = '005D3', time_start=time_block_start)\n",
    "comp_time_data.update({'5D3' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs\n",
    "dfmembrane_opm = pd.read_csv(op.join(qspace.DataOutput_dir, '005D1-OPM_membrane_data.csv'), index_col=0)\n",
    "dfmembrane_uniprot = pd.read_csv(op.join(qspace.DataOutput_dir, '005D2-Uniprot_membrane_data.csv'), index_col=0)\n",
    "dfmembrane_tmhmm = pd.read_csv(op.join(qspace.DataOutput_dir, '005D3-TMHMM_membrane_data.csv'), index_col=0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3,3)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "\n",
    "data = dfmembrane_opm\n",
    "i = 0 \n",
    "color= 'navy'\n",
    "ax[i][0].hist(data.angle.values, bins = 50, color = color)\n",
    "# ax[i][0].set_xlabel('Angle b/w planes')\n",
    "ax[i][1].hist(data.membrane_thickness.values, bins = 50, color = color)\n",
    "# ax[i][1].set_xlabel('Membrane Thickness (Angstroms)')\n",
    "ax[i][1].set_title(\"OPM\")\n",
    "\n",
    "areas = []\n",
    "for index, row in data.iterrows():\n",
    "    for leaf, area in ast.literal_eval(row.embedded_area).items():\n",
    "        areas += [area]\n",
    "n, bins, plot= ax[i][2].hist(areas, bins = 50, color = color)\n",
    "# ax[i][2].set_xlabel('Area (Angstroms^2)')\n",
    "\n",
    "data = dfmembrane_uniprot\n",
    "i = 1\n",
    "color= 'red'\n",
    "ax[i][0].hist(data.angle.values, bins = 50, color = color)\n",
    "# ax[i][0].set_xlabel('Angle b/w planes')\n",
    "ax[i][1].hist(data.membrane_thickness.values, bins = 50, color = color)\n",
    "# ax[i][1].set_xlabel('Membrane Thickness (Angstroms)')\n",
    "ax[i][1].set_title(\"UniProt\")\n",
    "\n",
    "areas = []\n",
    "for index, row in data.iterrows():\n",
    "    for leaf, area in ast.literal_eval(row.embedded_area).items():\n",
    "        areas += [area]\n",
    "n, bins, plot= ax[i][2].hist(areas, bins = 50, color = color)\n",
    "# ax[i][2].set_xlabel('Area (Angstroms^2)')\n",
    "data = dfmembrane_tmhmm\n",
    "i = 2\n",
    "color= 'purple'\n",
    "ax[i][0].hist(data.angle.values, bins = 50, color = color)\n",
    "ax[i][0].set_xlabel('Angle b/w planes')\n",
    "ax[i][1].hist(data.membrane_thickness.values, bins = 50, color = color)\n",
    "ax[i][1].set_xlabel('Membrane Thickness (Angstroms)')\n",
    "ax[i][1].set_title(\"TMHMM\")\n",
    "\n",
    "areas = []\n",
    "for index, row in data.iterrows():\n",
    "    for leaf, area in ast.literal_eval(row.embedded_area).items():\n",
    "        areas += [area]\n",
    "n, bins, plot= ax[i][2].hist(areas, bins = 50, color = color)\n",
    "ax[i][2].set_xlabel('Area (Angstroms^2)')\n",
    "\n",
    "for i in [0,1,2]:\n",
    "    ax[i][0].set_ylabel('Protein Structures')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 005E QCQA membrane calculations from OPM/Uniprot/DeepTMHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### imports needed for #005E\n",
    "\n",
    "structureFileLocations = pd.read_csv(op.join(qspace.DataOutput_dir, '005B-opmStructureLocations.csv'), index_col = 0 )\n",
    "structureOPMChains= structureFileLocations[structureFileLocations.origChain_opmChain != 'same_as_pdb'].origChain_opmChain.to_dict()\n",
    "# structureOPMChains = opmChains\n",
    "\n",
    "dfmembrane_opm = pd.read_csv(op.join(qspace.DataOutput_dir, '005D1-OPM_membrane_data.csv'), index_col=0)\n",
    "dfmembrane_uniprot = pd.read_csv(op.join(qspace.DataOutput_dir, '005D2-Uniprot_membrane_data.csv'), index_col=0)\n",
    "dfmembrane_tmhmm = pd.read_csv(op.join(qspace.DataOutput_dir, '005D3-TMHMM_membrane_data.csv'), index_col=0)\n",
    "\n",
    "membrane_calculations = {\"OPM\":dfmembrane_opm, \"Uniprot\":dfmembrane_uniprot, \"TMHMM\":dfmembrane_tmhmm}\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '004C-alldata_skeleton.csv')\n",
    "dfQuatProteome = pd.read_csv(infile, index_col=0)\n",
    "\n",
    "dfseq = op.join(qspace.DataOutput_dir, '001D-dfrepseq.csv')\n",
    "dfseq = pd.read_csv(dfseq, index_col=0)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# \n",
    "dfmembrane_opm[dfmembrane_opm.structureId.isin(['1af6-assembly1'])]\n",
    "dfmembrane_uniprot[dfmembrane_uniprot.structureId.isin(['1af6-assembly1'])]\n",
    "# dfmembrane_tmhmm[dfmembrane_tmhmm.structureId.isin(['1af6-assembly1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "\n",
    "membrane_calculations,dfsource = membraneModule.run_005E_combineMembraneData(membrane_calculations=membrane_calculations,\n",
    "                                                                                      )\n",
    "sharedDict = membraneModule.run_005E_UniOPMshared_bulbs(dfsource,structureOPMChains)\n",
    "dfsource, dfmissing = membraneModule.run_005E_auto_orient(sharedDict,dfsource)\n",
    "\n",
    "leaf_translation_failedQCQA = {\"AF-P02929-F1-model_v2\" :{'O': 'Periplasmic_C', 'N': 'Cytoplasmic'},\n",
    "                               \"AF-P45762-F1-model_v2\" : {'O': 'Periplasmic_C', 'N': 'Cytoplasmic'},\n",
    "                               'AF-P0AAE8-F1-model_v2' : {'O': 'Periplasmic_C', 'N': 'Cytoplasmic'},\n",
    "                              }\n",
    "\n",
    "missingleaves = {'AF-P02929-F1-model_v2' : ['Extracellular'],\n",
    "                 'AF-P45762-F1-model_v2' : ['Cytoplasmic'],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfsource, dfsourceNeedsManualCuration = membraneModule.run_005E_gapFillMissingTopoDomains(dfsource=dfsource,\n",
    "                                                                                          dfmissing=dfmissing,\n",
    "                                                                                          dfalldata = dfQuatProteome[dfQuatProteome.sfileChain_Residue.isna() == False],\n",
    "                                                                                          missingleaves=missingleaves,\n",
    "                                                                                          structureOPMChains=structureOPMChains,\n",
    "                                                                                          leaf_translation_failedQCQA= leaf_translation_failedQCQA,\n",
    "                                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsource,dfsource_final = membraneModule.run_005E_useManualOrient(dfsource = dfsource,\n",
    "                                                                  dfuni = dfmembrane_uniprot, \n",
    "                                                                  dftmhmm = dfmembrane_tmhmm,\n",
    "                                                                  membrane_calculations=membrane_calculations, \n",
    "                                                                  base = qspace.opmManualOrientDir\n",
    "                                                                 )\n",
    "\n",
    "global_orientation_dict,global_embedded_dict= membraneModule.run_005E_mapOrientationToProteome(dforientation=dfsource_final,\n",
    "                                                                                               dfalldata= dfQuatProteome,\n",
    "                                                                                               structureOPMChains=structureOPMChains,\n",
    "                                                                                               OPMcsvFolder = qspace.opmCsvDir,\n",
    "                                                                                               UniprotcsvFolder = qspace.UniprotCsvDir,\n",
    "                                                                                               TMHMMcsvFolder = qspace.TMHMMcsvDir,\n",
    "                                                                                              )\n",
    "\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '005E', time_start=time_block_start)\n",
    "comp_time_data.update({'5E' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 005F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dfnonMembraneOrientation = membraneModule.run_005F_assignCompartmentsEcocycAndGO(dfalldata = dfQuatProteome,\n",
    "                                                                      global_embedded_dict=global_embedded_dict,\n",
    "                                                                      global_orientation_dict=global_orientation_dict,\n",
    "                                                                      dfrepseq = dfseq,\n",
    "                                                                      ecocyc_file = op.join(qspace.Input_dir, '005A-EcocycSmartTable-All-genes-of-E.-coli-K-12-substr.-MG1655.txt'),        \n",
    "                                                                     )\n",
    "dfnonMembraneOrientation = membraneModule.run_005F_addComparmentsManually(dfnonMembraneOrientation,\n",
    "                                                               manualOrientFile = op.join(qspace.Input_dir,'005F-ManualCompartmentsForNonMembraneStructures.csv'),\n",
    "                                                               \n",
    "                                                              )\n",
    "\n",
    "proteinCompartment, aminoCompartment_dict,dfcompartments = membraneModule.run_005F_assignAALevelLocation(dforientation=dfnonMembraneOrientation,\n",
    "                                                                                                         dfalldata = dfQuatProteome,\n",
    "                                                                                                         data_int_orient=global_orientation_dict,\n",
    "                                                                                                         data_int_embed=global_embedded_dict,\n",
    "                                                                                                        )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '005F', time_start=time_block_start)\n",
    "comp_time_data.update({'5F' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Membrane / Subcellular Compartment Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural Properties (#006A-F)\n",
    "- <b>#006A</b> --  Disordered regions\n",
    "- <b>#006B</b> --  SCRATCH\n",
    "- <b>#006C</b> --  MS/MS\n",
    "- <b>#006D</b> --  Disulfide bridges\n",
    "- <b>#006E</b> --  protein-protein interfaces\n",
    "- <b>#006F</b> --  DSSP\n",
    "\n",
    "<!-- - <b>#003D</b> --  QCQA Alphafold Multimer models  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### imports needed for #006\n",
    "\n",
    "structureFileLocations = pd.read_csv(op.join(qspace.DataOutput_dir, '005B-opmStructureLocations.csv'), index_col = 0 )\n",
    "structureOPMChains= structureFileLocations[structureFileLocations.origChain_opmChain != 'same_as_pdb'].origChain_opmChain.to_dict()\n",
    "# structureOPMChains = opmChains\n",
    "\n",
    "dfmembrane_opm = pd.read_csv(op.join(qspace.DataOutput_dir, '005D1-OPM_membrane_data.csv'), index_col=0)\n",
    "dfmembrane_uniprot = pd.read_csv(op.join(qspace.DataOutput_dir, '005D2-Uniprot_membrane_data.csv'), index_col=0)\n",
    "dfmembrane_tmhmm = pd.read_csv(op.join(qspace.DataOutput_dir, '005D3-TMHMM_membrane_data.csv'), index_col=0)\n",
    "\n",
    "membrane_calculations = {\"OPM\":dfmembrane_opm, \"Uniprot\":dfmembrane_uniprot, \"TMHMM\":dfmembrane_tmhmm}\n",
    "\n",
    "infile = op.join(qspace.DataOutput_dir, '004C-alldata_skeleton.csv')\n",
    "dfQuatProteome = pd.read_csv(infile, index_col=0)\n",
    "\n",
    "dfseq = op.join(qspace.DataOutput_dir, '001D-dfrepseq.csv')\n",
    "dfseq = pd.read_csv(dfseq, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 006A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disembl_cmd = '/home/ecatoiu/Downloads/DisEMBL-1.4/DisEMBL.py'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "##### Fasta File Locations\n",
    "dfFastaLoc = structuralPropUtils.get_fastaFileLocations(dfalldata = dfQuatProteome)\n",
    "df_disemble,  disemble_global_info = structuralPropertiesModule.run_006A_Disembl(dfalldata = dfQuatProteome ,\n",
    "                                                                            disembl_cmd = disembl_cmd,\n",
    "                                                                          dfFastaLoc = dfFastaLoc)\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '006A', time_start=time_block_start)\n",
    "comp_time_data.update({'6A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 006B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_scratch ='/usr/bin/scratch/SCRATCH-1D_1.1/bin/run_SCRATCH-1D_predictors.sh'\n",
    "num_cores = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "structuralPropertiesModule.run_006B_SCRATCH(dfalldata= dfQuatProteome,                                      \n",
    "                                      dfFastaLoc=dfFastaLoc,\n",
    "                                      path_to_scratch= path_to_scratch,\n",
    "                                      num_cores = 4,\n",
    "                                      scratchFolderNEW = qspace.scratchResultsDir,\n",
    "                                      force_rerun= False)\n",
    "\n",
    "scratch_global_info = structuralPropertiesModule.run_006B_AAlevelSCRATCHannotation(dfalldata= dfQuatProteome,\n",
    "                                                                             scratchOutfolder = qspace.scratchResultsDir,\n",
    "                                                                            )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '006B', time_start=time_block_start)\n",
    "comp_time_data.update({'6B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 006C - NEEDS To be updated for current biopython version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_block_start = time.time()\n",
    "structuralProperties.run_006C_MSMS(dfalldata = dfQuatProteome,\n",
    "                                   MSMSoutfolder = qspaceDirs.msmsResultsDir,\n",
    "                                   outPDBfolder= qspaceDirs.cifToPdbFolder,\n",
    "                                   force_rerun = True,\n",
    "                                   force_rewrite_pdb = True\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "structuralProperties.run_006C_AAlevelMSMSannotation(dfalldata,\n",
    "                                                    dfstructure_file_locations)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "comp_time_data.update({'6C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 006D - Disulfide Bridges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "structuralPropertiesModule.run_006D_ssbioDisulfide(dfalldata =dfQuatProteome,\n",
    "                                             disulfideResultsFolder = qspace.disulfideDir,\n",
    "                                                   threshold = 3.0,\n",
    "                                            )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '006D', time_start=time_block_start)\n",
    "comp_time_data.update({'6D' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 006E - Protein/Protein Interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "structuralPropertiesModule.run_006E_geometricInterfaces(dfalldata = dfQuatProteome,\n",
    "                                                  outfolder= qspace.proteinInterfaceDir,\n",
    "                                                  force_rerun= force_rerun_global\n",
    "                                                 )\n",
    "\n",
    "global_interfaces=structuralPropertiesModule.run_006E_mapGeoInterfaceToProteome(dfalldata= dfQuatProteome,\n",
    "                                                                          interfaceFolder = qspace.proteinInterfaceDir\n",
    "                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_command_file = op.join(qspace.root_dir, 'ScanNetCommand/{}_qspace_input_to_SCANNET.txt'.format(ProjectName))\n",
    "path_to_scannet_progam = '../ScanNet/'\n",
    "scannetCommand , structureFileLocations= structuralPropertiesModule.generate_ScanNet_command(dfalldata = dfQuatProteome,\n",
    "                                                                                       commandFile = path_to_command_file, \n",
    "                                                                                       path_to_ScanNet = path_to_scannet_progam,\n",
    "                                                                                       force_rerun = force_rerun_global,\n",
    "                                                                                       scannetResultsFolder = qspace.scannetResultsDir,\n",
    "                                                                                       outPDBfolder = qspace.scannetStructuresDir,\n",
    "                                                                                      )\n",
    "print (scannetCommand)\n",
    "print (\"\\nInstall ScanNet at https://github.com/jertubiana/ScanNet\")\n",
    "print (\"In Terminal...\")\n",
    "print (\"> conda activate py_scannet\")\n",
    "print (\"> cd ScanNet\")\n",
    "print (\"> ./qspace_input_to_SCANNET.txt\") #runs all scannet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Run Scannet and Get Results^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scannetResults,global_scannet = structuralPropertiesModule.run_006E_readScannetResults(dfalldata = dfQuatProteome,\n",
    "                                                                                 dfstructure_file_locations= structureFileLocations,\n",
    "                                                                                 scannetFolder = qspace.scannetResultsDir,\n",
    "                                                                                 )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '006E', time_start=time_block_start)\n",
    "comp_time_data.update({'6E' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0006F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dssp_global_properties_dict = structuralPropertiesModule.run_006F_runDSSP(dfalldata= dfQuatProteome,\n",
    "                                                                    force_rerun = True,\n",
    "                                                                    dsspResultsFolder = qspace.dsspResultsDir,\n",
    "                                                                   )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '006F', time_start=time_block_start)\n",
    "comp_time_data.update({'6F' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Structural Properties Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and Mutants (#007A-D)\n",
    "- <b>#007A</b> --  Disordered regions\n",
    "- <b>#007B</b> --  SCRATCH\n",
    "- <b>#007C</b> --  MS/MS\n",
    "- <b>#007D</b> --  Disulfide bridges\n",
    "<!-- - <b>#006E</b> --  protein-protein interfaces -->\n",
    "<!-- - <b>#006F</b> --  DSSP -->\n",
    "\n",
    "<!-- - <b>#003D</b> --  QCQA Alphafold Multimer models  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()\n",
    "# inputs\n",
    "infile = op.join(qspace.DataOutput_dir, '004C-alldata_skeleton.csv')\n",
    "dfQuatProteome = pd.read_csv(infile, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "global_feature_dict= mutantFunctionModule.run_007A_functionalFeatures(dfalldata = dfQuatProteome,\n",
    "                                                                      force_rerun = force_rerun_global,\n",
    "                                                                      uniprotSeqDir = qspace.UniprotSeqsDir,\n",
    "                                                                      featuresUniprotDir = qspace.featuresUniprotDir,\n",
    "                                                                     )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '007A', time_start=time_block_start)\n",
    "comp_time_data.update({'7A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "ALEmutants,ALEgrantham = mutantFunctionModule.run_007B_mapALEmutants(dfalldata= dfQuatProteome,\n",
    "                           infile = op.join(qspace.Input_dir, '007B-ALE_mutations_input.csv'),\n",
    "                           )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '007B', time_start=time_block_start)\n",
    "comp_time_data.update({'7B' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)\n",
    "\n",
    "time_block_start = time.time()\n",
    "LTEEmutants,LTEEgrantham = mutantFunctionModule.run_007C_mapLTEEmutants(dfalldata= dfQuatProteome,\n",
    "                           infile = op.join(qspace.Input_dir, '007C-LTEE_mutations_input.csv'),\n",
    "                           )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '007C', time_start=time_block_start)\n",
    "comp_time_data.update({'7C' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "WTindex, WTcodons, WTcodonDomFreq, WTaas, WTaaDomFreq = mutantFunctionModule.run_007D_mapWTmutants(dfalldata = dfQuatProteome,\n",
    "                                                                                           alleleomeInputFolder='/home/ecatoiu/Projects/Nature_Alleleome/Alleleome_Data/dfz',\n",
    "                                                                                           force_realign = True,\n",
    "                                                                                           \n",
    "                                                                                          )\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '007D', time_start=time_block_start)\n",
    "comp_time_data.update({'7D' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Mutant / Functional Annotations Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalize Data Module (#008A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation time\n",
    "time_module_start = time.time()\n",
    "time_block_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "infile = op.join(qspace.DataOutput_dir, '004C-alldata_skeleton.csv')\n",
    "dfQuatProteome = pd.read_csv(infile, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_block_start = time.time()\n",
    "dfQuatProteomeFinal = compileDataModule.run_008A_finalizeDataframe(dfalldata = dfQuatProteome)\n",
    "print( '\\nComputation Time\\n--------------------------')\n",
    "time_point=get_computation_time(label = '008A', time_start=time_block_start)\n",
    "comp_time_data.update({'8A' : time_point})\n",
    "with open (op.join(qspace.DataOutput_dir, \"run_time_rerun_{}.json\".format(force_rerun_global)),'w' ) as f:\n",
    "    json.dump(comp_time_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '\\nComputation Time\\n--------------------------')\n",
    "get_computation_time(label = 'Compile All Data Module', time_start=time_module_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = pd.DataFrame()\n",
    "df_time['time_complete']  = pd.Series(comp_time_data)\n",
    "df_time.to_csv(op.join(qspace.DataOutput_dir, '008B-computation_time_forceRerun_{}.csv'.format(force_rerun_global)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _figuresModule import _fig4\n",
    "reload(_fig4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = _fig4.fig4E_aa(dfQuatProteomeFinal,fig = False, ax = False, save = False)\n",
    "# fig.savefig('Manuscript/GeneratedFigures/Fig4E_AAs.png',dpi = 300,transparent = True, bbox_inches = 'tight')\n",
    "fig, ax = _fig4.fig4E_prot(dfQuatProteomeFinal,fig = False, ax = False, save = False,legend = True)\n",
    "# fig.savefig('Manuscript/GeneratedFigures/Fig4E_Proteins.png',dpi = 300,transparent = True, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(6)\n",
    "\n",
    "max_y = 0\n",
    "\n",
    "colors = ['k','b','g']    \n",
    "cum_index_global = []\n",
    "\n",
    "for c, projectName in enumerate(['QSPACE-24_example','QSPACE-1515','QSPACE-GS']):\n",
    "    \n",
    "    \n",
    "    \n",
    "    time_unit = 60.*60. #hrs\n",
    "#     time_unit = 60. #min\n",
    "    for force_rerun in ['False']:\n",
    "#         if projectName == 'QSPACE-GS' and force_rerun == 'True':\n",
    "#             continue\n",
    "        try:\n",
    "            with open (op.join('data',projectName, \"run_time_rerun_{}.json\".format(force_rerun)),'r' ) as f:\n",
    "                comp_time = json.load(f)\n",
    "            df_time = pd.DataFrame()\n",
    "            df_time['time_complete']  = pd.Series(comp_time)\n",
    "\n",
    "            df_time['time_complete'] = df_time['time_complete'] / time_unit\n",
    "            print (projectName, force_rerun, len(df_time))\n",
    "#             df_time= pd.read_csv(op.join('data',projectName, '008B-computation_time_forceRerun_True.csv'),index_col=0)\n",
    "            df_time=df_time.sort_index() \n",
    "            cum_time = []\n",
    "            cum_index = []\n",
    "        \n",
    "            for index, row in df_time.iterrows():\n",
    "                if index not in cum_index_global:\n",
    "                    cum_index_global += [index]\n",
    "                cum_index += [index]\n",
    "                cum_time += [df_time[df_time.index.isin(cum_index)].time_complete.sum()]\n",
    "                \n",
    "            marker = ''\n",
    "            legend_label = '1st'\n",
    "            if force_rerun == 'False':\n",
    "                marker = 'o'\n",
    "                legend_label = '2nd'\n",
    "            ax.plot(list(range(len(cum_time))), cum_time, marker =marker, color = colors[c],linestyle ='-', label ='{} - {} Run'.format(projectName, legend_label))\n",
    "            time_annot =  '{:.1f} hrs'.format(df_time.time_complete.sum())\n",
    "            ax.annotate(time_annot, xy = (len(cum_time)-0.5,df_time.time_complete.sum() ), size = 14)\n",
    "            max_y = np.max([max_y , np.max(cum_time)])\n",
    "\n",
    "        except IOError:\n",
    "            pass\n",
    "\n",
    "        \n",
    "lw=2\n",
    "ax.set_xticks(list(range(len(cum_index_global))))\n",
    "ax.set_xticklabels(cum_index_global, rotation = 90)\n",
    "ax.plot((2,2), (0, max_y*100), color = 'k', linestyle = '--',lw=lw)\n",
    "ax.plot((7,7), (0, max_y*100), color = 'k', linestyle = '--',lw=lw)\n",
    "ax.plot((11,11), (0, max_y*100.), color = 'k', linestyle = '--',lw=lw)\n",
    "ax.plot((15,15), (0, max_y*100.), color = 'k', linestyle = '--',lw=lw)\n",
    "ax.plot((18,18), (0, max_y*100.), color = 'r', linestyle = '--',lw=lw)\n",
    "ax.plot((26,26), (0, max_y*100.), color = 'k', linestyle = '--',lw=lw)\n",
    "ax.plot((32,32), (0, max_y*100.), color = 'k', linestyle = '--',lw=lw)\n",
    "ax.plot((36,36), (0, max_y*100.), color = 'k', linestyle = '--',lw=lw)\n",
    "ax.plot((37,37), (0, max_y*100.), color = 'k', linestyle = '--',lw=lw)\n",
    "time_unit_label = {3600: 'Hours', 60: \"Minutes\"}\n",
    "ax.set_ylabel('Run Time ({})'.format(time_unit_label[time_unit]), size = 15)\n",
    "ax.set_xlabel('Module ID', size = 15)\n",
    "ax.set_xlim(-1,42)\n",
    "ax.legend(loc = (0.0,1.05), ncol = 3,fontsize = 10)\n",
    "ax.set_ylim(0.006,max_y*1.150)\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_yticks(np.linspace(0,1200,21))\n",
    "# ax.grid(True)\n",
    "for ax in [ax]:\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14,length = 8, width = 1.5,)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=14,length = 4, width = 1.5)\n",
    "    \n",
    "fig.savefig('Expected_run_times.png',dpi = 300,transparent = True, bbox_inches = 'tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
